Dataset: py150
Algorithm: ERM
Root dir: data1500-aug
Split scheme: official
Dataset kwargs: {}
Download: False
Frac: 1.0
Version: None
Unlabeled split: None
Unlabeled version: None
Use unlabeled y: False
Loader kwargs: {'num_workers': 4, 'pin_memory': True}
Unlabeled loader kwargs: {'num_workers': 8, 'pin_memory': True}
Train loader: standard
Uniform over groups: False
Distinct groups: None
N groups per batch: 2
Unlabeled n groups per batch: None
Batch size: 6
Unlabeled batch size: None
Eval loader: standard
Gradient accumulation steps: 1
Model: code-gpt-py
Model kwargs: {}
Noisystudent add dropout: None
Noisystudent dropout rate: None
Pretrained model path: None
Load featurizer only: False
Teacher model path: None
Transform: None
Additional train transform: None
Target resolution: None
Resize scale: None
Max token length: None
Randaugment n: 2
Loss function: lm_cross_entropy
Loss kwargs: {}
Groupby fields: ['repo']
Group dro step size: None
Coral penalty weight: 1.0
Dann penalty weight: None
Dann classifier lr: None
Dann featurizer lr: None
Dann discriminator lr: None
Afn penalty weight: None
Safn delta r: None
Hafn r: None
Use hafn: False
Irm lambda: 1.0
Irm penalty anneal iters: None
Self training lambda: None
Self training threshold: None
Pseudolabel t2: None
Soft pseudolabels: False
Algo log metric: multitask_accuracy
Process pseudolabels function: None
Val metric: acc
Val metric decreasing: False
N epochs: 3
Optimizer: AdamW
Lr: 8e-05
Weight decay: 0.0
Max grad norm: 1.0
Optimizer kwargs: {'eps': 1e-08}
Scheduler: linear_schedule_with_warmup
Scheduler kwargs: {'num_warmup_steps': 0}
Scheduler metric split: val
Scheduler metric name: None
Process outputs function: multiclass_logits_to_pred
Evaluate all splits: True
Eval splits: []
Eval only: False
Eval epoch: None
Device: cuda
Seed: 0
Log dir: logs/logs1500/mixed/all-for-1-per
Log every: 50
Save step: None
Save best: True
Save last: True
Save pred: True
No group logging: True
Progress bar: False
Resume: False
Use wandb: False
Wandb api key path: None
Wandb kwargs: {}
Use data parallel: False

Train data...
    n = 1500
Validation (OOD) data...
    n = 110
Test (OOD) data...
    n = 855
Validation (ID) data...
    n = 107
Test (ID) data...
    n = 428

Epoch [0]:

Train:
objective: 2.447
loss_all: 2.447
acc_all: 0.559

objective: 2.106
loss_all: 2.106
acc_all: 0.602

objective: 2.047
loss_all: 2.047
acc_all: 0.613

objective: 1.976
loss_all: 1.976
acc_all: 0.624

objective: 1.930
loss_all: 1.930
acc_all: 0.631

Epoch eval:
Acc (Class-Method): 0.569
Acc (Overall): 0.606
Acc (class): 0.573
Acc (method): 0.566
Acc (punctuation): 0.798
Acc (keyword): 0.600
Acc (builtin): 0.651
Acc (literal): 0.559
Acc (other_identifier): 0.455

Validation (OOD):
objective: 1.910
loss_all: 1.910
acc_all: 0.641

Epoch eval:
Acc (Class-Method): 0.633
Acc (Overall): 0.641
Acc (class): 0.652
Acc (method): 0.607
Acc (punctuation): 0.820
Acc (keyword): 0.643
Acc (builtin): 0.707
Acc (literal): 0.584
Acc (other_identifier): 0.488
Validation acc: 0.633
Epoch 0 has the best validation performance so far.


Epoch [1]:

Train:
objective: 1.540
loss_all: 1.540
acc_all: 0.686

objective: 1.506
loss_all: 1.506
acc_all: 0.689

objective: 1.550
loss_all: 1.550
acc_all: 0.684

objective: 1.515
loss_all: 1.515
acc_all: 0.686

objective: 1.545
loss_all: 1.545
acc_all: 0.683

Epoch eval:
Acc (Class-Method): 0.673
Acc (Overall): 0.685
Acc (class): 0.669
Acc (method): 0.678
Acc (punctuation): 0.863
Acc (keyword): 0.663
Acc (builtin): 0.717
Acc (literal): 0.641
Acc (other_identifier): 0.545

Validation (OOD):
objective: 1.908
loss_all: 1.908
acc_all: 0.644

Epoch eval:
Acc (Class-Method): 0.632
Acc (Overall): 0.644
Acc (class): 0.648
Acc (method): 0.611
Acc (punctuation): 0.833
Acc (keyword): 0.628
Acc (builtin): 0.721
Acc (literal): 0.582
Acc (other_identifier): 0.487
Validation acc: 0.632


Epoch [2]:

Train:
objective: 1.265
loss_all: 1.265
acc_all: 0.727

objective: 1.264
loss_all: 1.264
acc_all: 0.726

objective: 1.240
loss_all: 1.240
acc_all: 0.734

objective: 1.276
loss_all: 1.276
acc_all: 0.726

objective: 1.222
loss_all: 1.222
acc_all: 0.734

Epoch eval:
Acc (Class-Method): 0.727
Acc (Overall): 0.729
Acc (class): 0.711
Acc (method): 0.745
Acc (punctuation): 0.891
Acc (keyword): 0.690
Acc (builtin): 0.764
Acc (literal): 0.696
Acc (other_identifier): 0.601

Validation (OOD):
objective: 1.980
loss_all: 1.980
acc_all: 0.640

Epoch eval:
Acc (Class-Method): 0.618
Acc (Overall): 0.640
Acc (class): 0.634
Acc (method): 0.599
Acc (punctuation): 0.830
Acc (keyword): 0.635
Acc (builtin): 0.702
Acc (literal): 0.571
Acc (other_identifier): 0.486
Validation acc: 0.618

